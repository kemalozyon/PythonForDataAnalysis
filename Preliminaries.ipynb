{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6da1b8-9cab-4304-9188-da3b64799c6e",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## What Kinds of Data?\n",
    "\n",
    "- Tabular or spreadsheet-like data\n",
    "- Multidimensional arrays (matrices).\n",
    "- Multiple tables of data interrelated by key columns (what would be primary or foreign keys for a SQL user)\n",
    "- Evenly or unevenly spaced time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b0c16-f2bf-4051-8faa-ee21ce6db5f4",
   "metadata": {},
   "source": [
    "# Essential Python Libraries\n",
    "# 1. NumPy\n",
    "NumPy, short for Numerical Python, has long been a cornerstone of numerical computing in Python. It provides the data structures, algorithms, and library glue needed for most scientific applications involving numerical data in Python. NumPy contains, among other things:\n",
    "\n",
    "- A fast and efficient multidimensional array object ndarray\n",
    "\n",
    "- Functions for performing element-wise computations with arrays or mathematical operations between arrays\n",
    "\n",
    "- Tools for reading and writing array-based datasets to disk\n",
    "\n",
    "- Linear algebra operations, Fourier transform, and random number generation\n",
    "\n",
    "- A mature C API to enable Python extensions and native C or C++ code to access NumPy's data structures and computational facilities\n",
    "\n",
    "Beyond the fast array-processing capabilities that NumPy adds to Python, one of its primary uses in data analysis is as a container for data to be passed between algorithms and libraries. For numerical data, NumPy arrays are more efficient for storing and manipulating data than the other built-in Python data structures. Also, libraries written in a lower-level language, such as C or FORTRAN, can operate on the data stored in a NumPy array without copying data into some other memory representation. Thus, many numerical computing tools for Python either assume NumPy arrays as a primary data structure or else target interoperability with NumPy.\n",
    "# 2. pandas\n",
    "pandas provides high-level data structures and functions designed to make working with structured or tabular data intuitive and flexible. Since its emergence in 2010, it has helped enable Python to be a powerful and productive data analysis environment. The primary objects in pandas that will be used in this book are the DataFrame, a tabular, column-oriented data structure with both row and column labels, and the Series, a one-dimensional labeled array object.\n",
    "\n",
    "pandas blends the array-computing ideas of NumPy with the kinds of data manipulation capabilities found in spreadsheets and relational databases (such as SQL). It provides convenient indexing functionality to enable you to reshape, slice and dice, perform aggregations, and select subsets of data. Since data manipulation, preparation, and cleaning are such important skills in data analysis, pandas is one of the primary focuses of this book.\n",
    "\n",
    "As a bit of background, I started building pandas in early 2008 during my tenure at AQR Capital Management, a quantitative investment management firm. At the time, I had a distinct set of requirements that were not well addressed by any single tool at my disposal:\n",
    "\n",
    "- Data structures with labeled axes supporting automatic or explicit data alignment—this prevents common errors resulting from misaligned data and working with differently indexed data coming from different sources\n",
    "\n",
    "- Integrated time series functionality\n",
    "\n",
    "- The same data structures handle both time series data and non-time series data\n",
    "\n",
    "- Arithmetic operations and reductions that preserve metadata\n",
    "\n",
    "- Flexible handling of missing data\n",
    "\n",
    "- Merge and other relational operations found in popular databases (SQL-based, for example)\n",
    "\n",
    "I wanted to be able to do all of these things in one place, preferably in a language well suited to general-purpose software development. Python was a good candidate language for this, but at that time an integrated set of data structures and tools providing this functionality did not exist. As a result of having been built initially to solve finance and business analytics problems, pandas features especially deep time series functionality and tools well suited for working with time-indexed data generated by business processes.\n",
    "\n",
    "I spent a large part of 2011 and 2012 expanding pandas's capabilities with some of my former AQR colleagues, Adam Klein and Chang She. In 2013, I stopped being as involved in day-to-day project development, and pandas has since become a fully community-owned and community-maintained project with well over two thousand unique contributors around the world.\n",
    "\n",
    "For users of the R language for statistical computing, the DataFrame name will be familiar, as the object was named after the similar R data.frame object. Unlike Python, data frames are built into the R programming language and its standard library. As a result, many features found in pandas are typically either part of the R core implementation or provided by add-on packages.\n",
    "\n",
    "The pandas name itself is derived from panel data, an econometrics term for multidimensional structured datasets, and a play on the phrase Python data analysis.\n",
    "\n",
    "# 3. matplotlib\n",
    "matplotlib is the most popular Python library for producing plots and other two-dimensional data visualizations. It was originally created by John D. Hunter and is now maintained by a large team of developers. It is designed for creating plots suitable for publication. While there are other visualization libraries available to Python programmers, matplotlib is still widely used and integrates reasonably well with the rest of the ecosystem. I think it is a safe choice as a default visualization tool.\n",
    "\n",
    "# 4. IPython and Jupyter\n",
    "The IPython project began in 2001 as Fernando Pérez’s side project to make a better interactive Python interpreter. Over the subsequent 20 years it has become one of the most important tools in the modern Python data stack. While it does not provide any computational or data analytical tools by itself, IPython is designed for both interactive computing and software development work. It encourages an execute-explore workflow instead of the typical edit-compile-run workflow of many other programming languages. It also provides integrated access to your operating system’s shell and filesystem; this reduces the need to switch between a terminal window and a Python session in many cases. Since much of data analysis coding involves exploration, trial and error, and iteration, IPython can help you get the job done faster.\n",
    "\n",
    "In 2014, Fernando and the IPython team announced the Jupyter project, a broader initiative to design language-agnostic interactive computing tools. The IPython web notebook became the Jupyter notebook, with support now for over 40 programming languages. The IPython system can now be used as a kernel (a programming language mode) for using Python with Jupyter.\n",
    "\n",
    "IPython itself has become a component of the much broader Jupyter open source project, which provides a productive environment for interactive and exploratory computing. Its oldest and simplest \"mode\" is as an enhanced Python shell designed to accelerate the writing, testing, and debugging of Python code. You can also use the IPython system through the Jupyter notebook.\n",
    "\n",
    "The Jupyter notebook system also allows you to author content in Markdown and HTML, providing you a means to create rich documents with code and text.\n",
    "\n",
    "I personally use IPython and Jupyter regularly in my Python work, whether running, debugging, or testing code.\n",
    "\n",
    "In the accompanying book materials on GitHub, you will find Jupyter notebooks containing all the code examples from each chapter. If you cannot access GitHub where you are, you can try the mirror on Gitee.\n",
    "\n",
    "# 5. SciPy\n",
    "SciPy is a collection of packages addressing a number of foundational problems in scientific computing. Here are some of the tools it contains in its various modules:\n",
    "\n",
    "``scipy.integrate``\n",
    "Numerical integration routines and differential equation solvers\n",
    "\n",
    "``scipy.linalg``\n",
    "Linear algebra routines and matrix decompositions extending beyond those provided in ``numpy.linalg``\n",
    "\n",
    "``scipy.optimize``\n",
    "Function optimizers (minimizers) and root finding algorithms\n",
    "\n",
    "``scipy.signal``\n",
    "Signal processing tools\n",
    "\n",
    "``scipy.sparse``\n",
    "Sparse matrices and sparse linear system solvers\n",
    "\n",
    "``scipy.special``\n",
    "Wrapper around SPECFUN, a FORTRAN library implementing many common mathematical functions, such as the gamma function\n",
    "\n",
    "``scipy.stats``\n",
    "Standard continuous and discrete probability distributions (density functions, samplers, continuous distribution functions), various statistical tests, and more descriptive statistics\n",
    "\n",
    "Together, NumPy and SciPy form a reasonably complete and mature computational foundation for many traditional scientific computing applications.\n",
    "\n",
    "# 6. scikit-learn\n",
    "Since the project's inception in 2007, scikit-learn has become the premier general-purpose machine learning toolkit for Python programmers. As of this writing, more than two thousand different individuals have contributed code to the project. It includes submodules for such models as:\n",
    "\n",
    "- Classification: SVM, nearest neighbors, random forest, logistic regression, etc.\n",
    "\n",
    "- Regression: Lasso, ridge regression, etc.\n",
    "\n",
    "- Clustering: k-means, spectral clustering, etc.\n",
    "\n",
    "- Dimensionality reduction: PCA, feature selection, matrix factorization, etc.\n",
    "\n",
    "- Model selection: Grid search, cross-validation, metrics\n",
    "\n",
    "- Preprocessing: Feature extraction, normalization\n",
    "\n",
    "Along with pandas, statsmodels, and IPython, scikit-learn has been critical for enabling Python to be a productive data science programming language. While I won't be able to include a comprehensive guide to scikit-learn in this book, I will give a brief introduction to some of its models and how to use them with the other tools presented in the book.\n",
    "\n",
    "# 7. statsmodels\n",
    "statsmodels is a statistical analysis package that was seeded by work from Stanford University statistics professor Jonathan Taylor, who implemented a number of regression analysis models popular in the R programming language. Skipper Seabold and Josef Perktold formally created the new statsmodels project in 2010 and since then have grown the project to a critical mass of engaged users and contributors. Nathaniel Smith developed the Patsy project, which provides a formula or model specification framework for statsmodels inspired by R's formula system.\n",
    "\n",
    "Compared with scikit-learn, statsmodels contains algorithms for classical (primarily frequentist) statistics and econometrics. This includes such submodules as:\n",
    "\n",
    "- Regression models: linear regression, generalized linear models, robust linear models, linear mixed effects models, etc.\n",
    "\n",
    "- Analysis of variance (ANOVA)\n",
    "\n",
    "- Time series analysis: AR, ARMA, ARIMA, VAR, and other models\n",
    "\n",
    "- Nonparametric methods: Kernel density estimation, kernel regression\n",
    "\n",
    "- Visualization of statistical model results\n",
    "\n",
    "statsmodels is more focused on statistical inference, providing uncertainty estimates and p-values for parameters. scikit-learn, by contrast, is more prediction focused.\n",
    "\n",
    "As with scikit-learn, I will give a brief introduction to statsmodels and how to use it with NumPy and pandas.\n",
    "\n",
    "# Other Packages\n",
    "In 2022, there are many other Python libraries which might be discussed in a book about data science. This includes some newer projects like TensorFlow or PyTorch, which have become popular for machine learning or artificial intelligence work. Now that there are other books out there that focus more specifically on those projects, I would recommend using this book to build a foundation in general-purpose Python data wrangling. Then, you should be well prepared to move on to a more advanced resource that may assume a certain level of expertise.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2ce0a-f59d-437f-b0ea-c8cd6e47425f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
